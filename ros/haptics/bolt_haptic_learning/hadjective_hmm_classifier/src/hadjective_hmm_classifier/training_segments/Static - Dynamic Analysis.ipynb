{
 "metadata": {
  "name": "Static - Dynamic Analysis"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn\n",
      "import load_static_features\n",
      "import utilities\n",
      "from sklearn.metrics import f1_score\n",
      "%pylab inline\n",
      "figsize(10,5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Welcome to pylab, a matplotlib-based Python environment [backend: module://IPython.zmq.pylab.backend_inline].\n",
        "For more information, type 'help(pylab)'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading the static features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_features = load_static_features.load_adjective_phase(\"/home/pezzotto/log/static_features/\")\n",
      "static_train_features = {}\n",
      "static_test_features = {}\n",
      "for adj in utilities.adjectives:\n",
      "    adj_dict = all_features[adj]\n",
      "    all_motions_train_pos = hstack([v['train']['features'][v['train']['labels'] > 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for train\n",
      "    all_motions_train_neg = hstack([v['train']['features'][v['train']['labels'] <= 0, :] #select only negative examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for train\n",
      "    all_motions_test_pos = hstack([v['test']['features'] [v['test']['labels'] > 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for test\n",
      "    all_motions_test_neg = hstack([v['test']['features'] [v['test']['labels'] <= 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for test    \n",
      "    static_train_features[adj] = {'pos': all_motions_train_pos, 'neg': all_motions_train_neg}\n",
      "    static_test_features[adj] = {'pos': all_motions_test_pos, 'neg': all_motions_test_neg}    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading the dynamic features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_features = load_static_features.load_adjective_phase(\"/home/pezzotto/log/hmm_features/\")\n",
      "dynamic_train_features = {}\n",
      "dynamic_test_features = {}\n",
      "for adj in utilities.adjectives:\n",
      "    adj_dict = all_features[adj]\n",
      "    all_motions_train_pos = hstack([v['train']['features'][v['train']['labels'] > 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for train\n",
      "    all_motions_train_neg = hstack([v['train']['features'][v['train']['labels'] <= 0, :] #select only negative examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for train\n",
      "    all_motions_test_pos = hstack([v['test']['features'] [v['test']['labels'] > 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for test\n",
      "    all_motions_test_neg = hstack([v['test']['features'] [v['test']['labels'] <= 0, :] #select only positive examples\n",
      "            for v in adj_dict.values()]) #getting a big matrix for test    \n",
      "    dynamic_train_features[adj] = {'pos': all_motions_train_pos, 'neg': all_motions_train_neg}\n",
      "    dynamic_test_features[adj] = {'pos': all_motions_test_pos, 'neg': all_motions_test_neg}   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Putting together all the features"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_train_features = {}\n",
      "combined_test_features = {}\n",
      "for (adj, static), (_,dynamic) in zip(static_train_features.iteritems(), dynamic_train_features.iteritems()):\n",
      "    pos = hstack((static['pos'], dynamic['pos']))\n",
      "    neg = hstack((static['neg'], dynamic['neg']))\n",
      "    combined_train_features[adj] = {'pos':pos, 'neg':neg}\n",
      "for (adj, static), (_,dynamic) in zip(static_test_features.iteritems(), dynamic_test_features.iteritems()):\n",
      "    pos = hstack((static['pos'], dynamic['pos']))\n",
      "    neg = hstack((static['neg'], dynamic['neg']))\n",
      "    combined_test_features[adj] = {'pos':pos, 'neg':neg}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying adjective squishy. Remember it had $0.2$ on the static test set, and $0$ on the dynamic"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "adj = 'squishy'\n",
      "train_set = combined_train_features[adj]\n",
      "test_set = combined_test_features[adj]\n",
      "train_X = vstack((train_set['pos'], train_set['neg'])) #data\n",
      "train_Y = ([1] * train_set['pos'].shape[0]) + ([0] * train_set['neg'].shape[0]) #labels\n",
      "test_X = vstack((test_set['pos'], test_set['neg'])) #data\n",
      "test_Y = ([1] * test_set['pos'].shape[0]) + ([0] * test_set['neg'].shape[0]) #labels"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I had tried PCA here, and the results where really bad (like $0\\%$ score). **Take home message**: don't reduce the data with PCA!!!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's go with SVMs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {'C': np.linspace(0.001,1e6,100),              \n",
      "              'penalty': ['l2','l1'],\n",
      "              'dual': [False],\n",
      "              'class_weight' : ('auto',),\n",
      "              }\n",
      "clf = sklearn.svm.LinearSVC()\n",
      "grid = sklearn.grid_search.GridSearchCV(clf, parameters, n_jobs=10, score_func=f1_score)\n",
      "grid.fit(train_X, train_Y)\n",
      "clf = grid.best_estimator_\n",
      "print \"F1 score on training: \", f1_score(train_Y, clf.predict(train_X))\n",
      "print \"F1 score on testing: \", f1_score(test_Y, clf.predict(test_X))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1 score on training:  1.0\n",
        "F1 score on testing:  0.766666666667\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How about other types of SVM?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parameters = {'C': np.linspace(0.001,1e6,100),              \n",
      "              'kernel': ['rbf'],\n",
      "              'class_weight' : ('auto',),\n",
      "              }\n",
      "clf = sklearn.svm.SVC()\n",
      "grid = sklearn.grid_search.GridSearchCV(clf, parameters, n_jobs=10, score_func=f1_score)\n",
      "grid.fit(train_X, train_Y)\n",
      "clf = grid.best_estimator_\n",
      "print \"F1 score on training: \", f1_score(train_Y, clf.predict(train_X))\n",
      "print \"F1 score on testing: \", f1_score(test_Y, clf.predict(test_X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1 score on training:  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.567567567568\n",
        "F1 score on testing:  0.6\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I have tried with polynomial and sigmoid kernels too, and the **results are no better**. For some strange reason training with SVC (instead of LinearSVC) is terribly slow. Linear kernels should be the best option then."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#parameters = {'C': np.linspace(0.001,1e6,100),              \n",
      "#              'kernel': ['poly', 'sigmoid'],\n",
      "#              'degree': [1,2,3,4,5],\n",
      "#              'class_weight' : ('auto',),\n",
      "#              }\n",
      "#clf = sklearn.svm.SVC()\n",
      "#grid = sklearn.grid_search.GridSearchCV(clf, parameters, n_jobs=1, score_func=f1_score, verbose=10)\n",
      "#grid.fit(train_X, train_Y)\n",
      "#clf = grid.best_estimator_\n",
      "#print \"F1 score on training: \", f1_score(train_Y, clf.predict(train_X))\n",
      "#print \"F1 score on testing: \", f1_score(test_Y, clf.predict(test_X))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}